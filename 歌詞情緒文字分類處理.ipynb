{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##語庫資料鍵入\n",
    "with open('na.txt', 'r',encoding = 'utf8') as f:\n",
    "    change_str = f.read()\n",
    "    words=change_str.replace(\"\\t\",'').replace(\"\\n\",'\",\"')\n",
    "    with open(\"na1.txt\",\"w\",encoding=\"utf8\") as f1:\n",
    "        f1.write('\"'+words+'\"')\n",
    "        \n",
    "itemize=[\"NA\",\"NB\",\"NC\",\"ND\",\"NE\",\"NG\",\"NH\",\"NI\",\"NJ\",\"NK\",\"NL\",\"NN\",\"PA\",\"PB\",\"PC\",\"PD\",\"PE\",\"PF\",\"PG\",\"PH\",\"PK\"]\n",
    "label=[['NA'],['NB'],['NC'],['ND'],['NE'],['NG'],['NH'],['NI'],['NJ'],['NK'],['NL'],['NN'],['PA'],['PB'],['PC'],['PD'],['PE'],['PF'],['PG'],['PH'],['PK']]\n",
    "\n",
    "with open(\"stopwords.txt\",\"r\",encoding = 'utf8') as f:\n",
    "    stopword_set=f.read().split(\"\\n\")\n",
    "\n",
    "##資料處理，並將語庫的詞鍵入DATA的LIST中，以便後續處理\n",
    "data=[]\n",
    "for i in range(-1,20):\n",
    "    data.append(words.split(itemize[i])[1].split(itemize[i+1])[0])\n",
    "    \n",
    "pp=data.pop(0)\n",
    "data.append(pp)\n",
    "\n",
    "##將情緒標籤(itemize)當作KEY，將data中匹配的文字建立成字典\n",
    "datasp=[]\n",
    "datain={}\n",
    "for j in range(-1,20):\n",
    "        datasp=str(data[j]).split('\",\"')\n",
    "        datain[itemize[j]]=datasp\n",
    "\n",
    "##將情緒標籤建立字典\n",
    "##key:情緒標籤 value:之後鍵入的情緒相似度數值(目前為0)\n",
    "dictwor={}\n",
    "for i in range(len(itemize)):\n",
    "    dictwor[itemize[i]]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tStart = time.time()#計時開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\BIGDAT~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.679 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "##開啟需要預測的詞檔案\n",
    "query = open(\"input.txt\",'r',encoding = 'utf8')\n",
    "tokens = jieba.lcut(query.read(), HMM=True) #.lcut將切好的多個字變成字串\n",
    "\n",
    "q_list = []\n",
    "for token in tokens:\n",
    "     if token not in stopword_set:\n",
    "        q_list.append(token)\n",
    "\n",
    "##建立欲預測詞的字典，用來容納算出來的100個詞\n",
    "##KEY:預測詞  VALUE：在字庫中相似的前100個詞\n",
    "predword={} \n",
    "for i in range(len(q_list)):\n",
    "    predword[q_list[i]]=\"0\"\n",
    "    \n",
    "query.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\big data\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "c:\\users\\big data\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上班end\n",
      "累end\n",
      "闆end\n",
      "討厭end\n"
     ]
    }
   ],
   "source": [
    "##使用word2vec\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "\n",
    "##匯入已經使用維基百科條目訓練好的model\n",
    "model = models.Word2Vec.load('word2vec.model')\n",
    "\n",
    "##建立放置相似度分數的字典\n",
    "##key:預測詞 value:預測詞運算分數字典\n",
    "dictwor2={}\n",
    "\n",
    "##第一步：先搜尋是否被切出來的詞與情緒語庫的文字有所相同，若有，直接貼上標籤。\n",
    "for keyword in predword.keys():      \n",
    "    for inword in predword[keyword]:    \n",
    "        count={}\n",
    "        for i in range(-1,20):\n",
    "            a=str(itemize[i+1])\n",
    "            if keyword in datain[a]: \n",
    "                dictwor2[keyword]=[a,1000]\n",
    "                break\n",
    "            else:continue\n",
    "    \n",
    "##第二步：若沒有相符的文字，則利用word2vec與情緒語庫進行相似度比對，出來的分數加總若最高則該預測詞標籤為該分數最高的標籤\n",
    "for keyword in predword.keys():      \n",
    "    if keyword not in dictwor2.keys():    \n",
    "            count={}\n",
    "            for i in range(-1,20):\n",
    "                a=str(itemize[i+1])                        \n",
    "                wordcount=0\n",
    "                emsimsum=0\n",
    "                for j in range(len(datain[itemize[i+1]])):\n",
    "                    try:\n",
    "                        emsimsum+=model.similarity(keyword,datain[itemize[i+1]][j])\n",
    "                        inwordcount+=1\n",
    "                    except Exception as e:\n",
    "                        repr(e)\n",
    "                        continue\n",
    "                count[a]=emsimsum/(wordcount+1)\n",
    "                dictwor2[keyword]=count\n",
    "    print(keyword+\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'討厭': 'NN', '上班': 'NN', '累': 'NN', '闆': 'NA'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##排序並且抽取出分數最高的情緒標籤\n",
    "##key:預測詞 values:最高分數的標籤\n",
    "worddict={}\n",
    "\n",
    "for j in dictwor2:\n",
    "    if type(dictwor2[j]) == list:\n",
    "        worddict[j]=dictwor2[j][0]\n",
    "    else:\n",
    "        worddict[j]=sorted(dictwor2[j].items(),key=lambda item:item[1], reverse = 1 )[0][0]\n",
    "\n",
    "worddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n"
     ]
    }
   ],
   "source": [
    "##key:label value:計數\n",
    "emolabelcount={}\n",
    "elist=list(worddict.values())\n",
    "\n",
    "for i in range(-1,20):\n",
    "    a=str(itemize[i+1])  \n",
    "    emolabelcount[a]=elist.count(a)\n",
    "\n",
    "sentenceemotion=sorted(emolabelcount.items(),key=lambda item:item[1], reverse = 1 )[0][0]\n",
    "print(sentenceemotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.509620189666748\n"
     ]
    }
   ],
   "source": [
    "tEnd = time.time()#計時結束\n",
    "print(tEnd-tStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
