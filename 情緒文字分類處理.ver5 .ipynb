{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\BIGDAT~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.658 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "c:\\users\\big data\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:72: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上班end\n",
      "累end\n",
      "闆end\n",
      "討厭end\n",
      "NN\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "\n",
    "emotionless={}\n",
    "##語庫資料鍵入\n",
    "with open('emotionless1.txt', 'r',encoding = 'utf8') as f:\n",
    "    a=f.read().split(\"\\t\")\n",
    "    for i in range(0,len(a),2):\n",
    "        label=a[i]\n",
    "        inword=a[i+1].split(\" \")\n",
    "        emotionless[label]=inword\n",
    "        \n",
    "        \n",
    "itemize=[\"NA\",\"NB\",\"NC\",\"ND\",\"NE\",\"NG\",\"NH\",\"NI\",\"NJ\",\"NK\",\"NL\",\"NN\",\"PA\",\"PB\",\"PC\",\"PD\",\"PE\",\"PF\",\"PG\",\"PH\",\"PK\"]\n",
    "label=[['NA'],['NB'],['NC'],['ND'],['NE'],['NG'],['NH'],['NI'],['NJ'],['NK'],['NL'],['NN'],['PA'],['PB'],['PC'],['PD'],['PE'],['PF'],['PG'],['PH'],['PK']]\n",
    "\n",
    "with open(\"stopwords.txt\",\"r\",encoding = 'utf8') as f:\n",
    "    stopword_set=f.read().split(\"\\n\")\n",
    "\n",
    "##將情緒標籤建立字典\n",
    "##key:情緒標籤 value:之後鍵入的情緒相似度數值(目前為0)\n",
    "dictwor={}\n",
    "for i in range(len(itemize)):\n",
    "    dictwor[itemize[i]]=0\n",
    "\n",
    "    \n",
    "##開啟需要預測的詞檔案\n",
    "with open(\"input.txt\",'r',encoding = 'utf8') as f:\n",
    "    tokens = jieba.lcut(f.read(), HMM=True) #.lcut將切好的多個字變成字串\n",
    "\n",
    "    q_list = []\n",
    "    for token in tokens:\n",
    "         if token not in stopword_set:\n",
    "            q_list.append(token)\n",
    "\n",
    "    ##建立欲預測詞的字典，用來容納算出來的100個詞\n",
    "    ##KEY:預測詞  VALUE：在字庫中相似的前100個詞\n",
    "    predword={} \n",
    "    for i in range(len(q_list)):\n",
    "        predword[q_list[i]]=\"0\"\n",
    "      \n",
    "##使用word2vec\n",
    "##匯入已經使用維基百科條目訓練好的model\n",
    "model = models.Word2Vec.load('word2vec.model')\n",
    "\n",
    "##建立放置相似度分數的字典\n",
    "##key:預測詞 value:預測詞運算分數字典\n",
    "dictwor2={}\n",
    "\n",
    "##第一步：先搜尋是否被切出來的詞與情緒語庫的文字有所相同，若有，直接貼上標籤。\n",
    "for keyword in predword.keys():      \n",
    "    for inword in predword[keyword]:    \n",
    "        count={}\n",
    "        for i in range(-1,20):\n",
    "            a=str(itemize[i+1])\n",
    "            if keyword in emotionless[a]: \n",
    "                dictwor2[keyword]=[a,1000]\n",
    "                break\n",
    "            else:continue\n",
    "    \n",
    "##第二步：若沒有相符的文字，則利用word2vec與情緒語庫進行相似度比對，出來的分數加總若最高則該預測詞標籤為該分數最高的標籤\n",
    "for keyword in predword.keys():      \n",
    "    if keyword not in dictwor2.keys():    \n",
    "            count={}\n",
    "            for i in range(-1,20):\n",
    "                a=str(itemize[i+1])                        \n",
    "                wordcount=0\n",
    "                emsimsum=0\n",
    "                for j in range(len(emotionless[itemize[i+1]])):\n",
    "                    try:\n",
    "                        emsimsum+=model.similarity(keyword,emotionless[itemize[i+1]][j])\n",
    "                        inwordcount+=1\n",
    "                    except Exception as e:\n",
    "                        repr(e)\n",
    "                        continue\n",
    "                count[a]=emsimsum/(wordcount+1)\n",
    "                dictwor2[keyword]=count\n",
    "    print(keyword+\"end\")\n",
    "\n",
    "##排序並且抽取出分數最高的情緒標籤\n",
    "##key:預測詞 values:最高分數的標籤\n",
    "worddict={}\n",
    "\n",
    "for j in dictwor2:\n",
    "    if type(dictwor2[j]) == list:\n",
    "        worddict[j]=dictwor2[j][0]\n",
    "    else:\n",
    "        worddict[j]=sorted(dictwor2[j].items(),key=lambda item:item[1], reverse = 1 )[0][0]\n",
    "\n",
    "##key:label value:計數\n",
    "emolabelcount={}\n",
    "elist=list(worddict.values())\n",
    "\n",
    "for i in range(-1,20):\n",
    "    a=str(itemize[i+1])  \n",
    "    emolabelcount[a]=elist.count(a)\n",
    "\n",
    "sentenceemotion=sorted(emolabelcount.items(),key=lambda item:item[1], reverse = 1 )[0][0]\n",
    "print(sentenceemotion)\n",
    "with open (\".\\sentencewmotionoutput\\sentenceemot.txt\",\"w\") as f1:\n",
    "    f1.write(sentenceemotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
